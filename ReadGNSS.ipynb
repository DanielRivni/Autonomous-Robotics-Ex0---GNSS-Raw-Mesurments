{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running this block required only in the first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: simplekml in c:\\anaconda\\lib\\site-packages (1.3.6)\n",
      "Requirement already satisfied: georinex in c:\\anaconda\\lib\\site-packages (1.16.2)\n",
      "Requirement already satisfied: xarray in c:\\anaconda\\lib\\site-packages (2023.6.0)\n",
      "Requirement already satisfied: unlzw3 in c:\\anaconda\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: navpy in c:\\anaconda\\lib\\site-packages (1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\anaconda\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: hatanaka in c:\\anaconda\\lib\\site-packages (from georinex) (2.8.1)\n",
      "Requirement already satisfied: ncompress in c:\\anaconda\\lib\\site-packages (from georinex) (1.0.2)\n",
      "Requirement already satisfied: netcdf4 in c:\\anaconda\\lib\\site-packages (from georinex) (1.6.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\anaconda\\lib\\site-packages (from hatanaka->georinex) (6.4.0)\n",
      "Requirement already satisfied: cftime in c:\\anaconda\\lib\\site-packages (from netcdf4->georinex) (1.6.3)\n",
      "Requirement already satisfied: certifi in c:\\anaconda\\lib\\site-packages (from netcdf4->georinex) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas matplotlib simplekml georinex xarray unlzw3 navpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, csv\n",
    "parent_directory = os.path.split(os.getcwd())[0]\n",
    "ephemeris_data_directory = os.path.join(parent_directory, 'data')\n",
    "sys.path.insert(0, parent_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the input_filepath according to your path to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_filepath = 'C:/Users/דניאל ריבני/Desktop/רובוטים/gnss_log_2024_05_06_21_24_38 (1).txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(input_filepath) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if row[0][0] == '#':\n",
    "            if 'Fix' in row[0]:\n",
    "                android_fixes = [row[1:]]\n",
    "            elif 'Raw' in row[0]:\n",
    "                measurements = [row[1:]]\n",
    "        else:\n",
    "            if row[0] == 'Fix':\n",
    "                android_fixes.append(row[1:])\n",
    "            elif row[0] == 'Raw':\n",
    "                measurements.append(row[1:])\n",
    "\n",
    "android_fixes = pd.DataFrame(android_fixes[1:], columns = android_fixes[0])\n",
    "measurements = pd.DataFrame(measurements[1:], columns = measurements[0])\n",
    "\n",
    "# Format satellite IDs\n",
    "measurements.loc[measurements['Svid'].str.len() == 1, 'Svid'] = '0' + measurements['Svid']\n",
    "measurements.loc[measurements['ConstellationType'] == '1', 'Constellation'] = 'G'\n",
    "measurements.loc[measurements['ConstellationType'] == '3', 'Constellation'] = 'R'\n",
    "measurements['SvName'] = measurements['Constellation'] + measurements['Svid']\n",
    "\n",
    "# Remove all non-GPS measurements\n",
    "measurements = measurements.loc[measurements['Constellation'] == 'G']\n",
    "\n",
    "# Convert columns to numeric representation\n",
    "measurements['Cn0DbHz'] = pd.to_numeric(measurements['Cn0DbHz'])\n",
    "measurements['TimeNanos'] = pd.to_numeric(measurements['TimeNanos'])\n",
    "measurements['FullBiasNanos'] = pd.to_numeric(measurements['FullBiasNanos'])\n",
    "measurements['ReceivedSvTimeNanos']  = pd.to_numeric(measurements['ReceivedSvTimeNanos'])\n",
    "measurements['PseudorangeRateMetersPerSecond'] = pd.to_numeric(measurements['PseudorangeRateMetersPerSecond'])\n",
    "measurements['ReceivedSvTimeUncertaintyNanos'] = pd.to_numeric(measurements['ReceivedSvTimeUncertaintyNanos'])\n",
    "\n",
    "# A few measurement values are not provided by all phones\n",
    "if 'BiasNanos' in measurements.columns:\n",
    "    measurements['BiasNanos'] = pd.to_numeric(measurements['BiasNanos'])\n",
    "else:\n",
    "    measurements['BiasNanos'] = 0\n",
    "if 'TimeOffsetNanos' in measurements.columns:\n",
    "    measurements['TimeOffsetNanos'] = pd.to_numeric(measurements['TimeOffsetNanos'])\n",
    "else:\n",
    "    measurements['TimeOffsetNanos'] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final GPS Time: 0      2024-05-06 18:24:56.592145664+00:00\n",
      "1      2024-05-06 18:24:56.592145664+00:00\n",
      "2      2024-05-06 18:24:56.592145664+00:00\n",
      "3      2024-05-06 18:24:56.592145664+00:00\n",
      "4      2024-05-06 18:24:56.592145664+00:00\n",
      "                       ...                \n",
      "1832   2024-05-06 18:25:59.417842176+00:00\n",
      "1856   2024-05-06 18:25:59.417842176+00:00\n",
      "1857   2024-05-06 18:25:59.417842176+00:00\n",
      "1858   2024-05-06 18:25:59.417842176+00:00\n",
      "1859   2024-05-06 18:25:59.417842176+00:00\n",
      "Name: UnixTime, Length: 590, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "measurements['GpsTimeNanos'] = measurements['TimeNanos'] - (measurements['FullBiasNanos'] - measurements['BiasNanos'])\n",
    "gpsepoch = datetime(1980, 1, 6, 0, 0, 0)\n",
    "measurements['UnixTime'] = pd.to_datetime(measurements['GpsTimeNanos'], utc = True, origin=gpsepoch)\n",
    "measurements['UnixTime'] = measurements['UnixTime']\n",
    "\n",
    "# Split data into measurement epochs\n",
    "measurements['Epoch'] = 0\n",
    "measurements.loc[measurements['UnixTime'] - measurements['UnixTime'].shift() > timedelta(milliseconds=200), 'Epoch'] = 1\n",
    "measurements['Epoch'] = measurements['Epoch'].cumsum()\n",
    "\n",
    "print(\"Final GPS Time:\", measurements['UnixTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudorange (in meters): 0       4.577729e+13\n",
      "1       4.577729e+13\n",
      "2       4.577729e+13\n",
      "3       4.577729e+13\n",
      "4       4.577729e+13\n",
      "            ...     \n",
      "1832    2.001117e+07\n",
      "1856    1.884998e+07\n",
      "1857    1.900045e+07\n",
      "1858    2.148261e+07\n",
      "1859    2.259022e+07\n",
      "Name: PrM, Length: 590, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "WEEKSEC = 604800\n",
    "LIGHTSPEED = 2.99792458e8\n",
    "\n",
    "# This should account for rollovers since it uses a week number specific to each measurement\n",
    "\n",
    "measurements['tRxGnssNanos'] = measurements['TimeNanos'] + measurements['TimeOffsetNanos'] - (measurements['FullBiasNanos'].iloc[0] + measurements['BiasNanos'].iloc[0])\n",
    "measurements['GpsWeekNumber'] = np.floor(1e-9 * measurements['tRxGnssNanos'] / WEEKSEC)\n",
    "measurements['tRxSeconds'] = 1e-9*measurements['tRxGnssNanos'] - WEEKSEC * measurements['GpsWeekNumber']\n",
    "measurements['tTxSeconds'] = 1e-9*(measurements['ReceivedSvTimeNanos'] + measurements['TimeOffsetNanos'])\n",
    "# Calculate pseudorange in seconds\n",
    "measurements['prSeconds'] = measurements['tRxSeconds'] - measurements['tTxSeconds']\n",
    "\n",
    "# Conver to meters\n",
    "measurements['PrM'] = LIGHTSPEED * measurements['prSeconds']\n",
    "measurements['PrSigmaM'] = LIGHTSPEED * 1e-9 * measurements['ReceivedSvTimeUncertaintyNanos']\n",
    "\n",
    "print(\"Pseudorange (in meters):\", measurements['PrM'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EphemerisManager library (see in: https://www.johnsonmitchelld.com/2021/03/14/least-squares-gps.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP_TLS, FTP\n",
    "import ftplib\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import georinex\n",
    "import xarray\n",
    "import unlzw3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EphemerisManager():\n",
    "    def __init__(self, data_directory=os.path.join(os.getcwd(), 'data', 'ephemeris')):\n",
    "        self.data_directory = data_directory\n",
    "        nasa_dir = os.path.join(data_directory, 'nasa')\n",
    "        igs_dir = os.path.join(data_directory, 'igs')\n",
    "        os.makedirs(nasa_dir, exist_ok=True)\n",
    "        os.makedirs(igs_dir, exist_ok=True)\n",
    "        self.data = None\n",
    "        self.leapseconds = None\n",
    "\n",
    "    def get_ephemeris(self, timestamp, satellites):\n",
    "        systems = EphemerisManager.get_constellations(satellites)\n",
    "        if not isinstance(self.data, pd.DataFrame):\n",
    "            self.load_data(timestamp, systems)\n",
    "        data = self.data\n",
    "        if satellites:\n",
    "            data = data.loc[data['sv'].isin(satellites)]\n",
    "        data = data.loc[data['time'] < timestamp]\n",
    "        data = data.sort_values('time').groupby('sv').last()\n",
    "        data['Leap Seconds'] = self.leapseconds\n",
    "        return data\n",
    "\n",
    "    def get_leapseconds(self, timestamp):\n",
    "        return self.leapseconds\n",
    "\n",
    "    def load_data(self, timestamp, constellations=None):\n",
    "        filepaths = EphemerisManager.get_filepaths(timestamp)\n",
    "        data_list = []\n",
    "        timestamp_age = datetime.now(timezone.utc) - timestamp\n",
    "        if constellations == None:\n",
    "            for fileinfo in filepaths.values():\n",
    "                data = self.get_ephemeris_dataframe(fileinfo)\n",
    "                data_list.append(data)\n",
    "        else:\n",
    "            legacy_systems = set(['G', 'R'])\n",
    "            legacy_systems_only = len(constellations - legacy_systems) == 0\n",
    "            if timestamp_age.days > 0:\n",
    "                if legacy_systems_only:\n",
    "                    data_list.append(self.get_ephemeris_dataframe(\n",
    "                        filepaths['nasa_daily_gps']))\n",
    "                    if 'R' in constellations:\n",
    "                        data_list.append(self.get_ephemeris_dataframe(\n",
    "                            filepaths['nasa_daily_glonass']))\n",
    "                else:\n",
    "                    data_list.append(self.get_ephemeris_dataframe(\n",
    "                        filepaths['nasa_daily_combined']))\n",
    "            else:\n",
    "                data_list.append(self.get_ephemeris_dataframe(\n",
    "                    filepaths['nasa_daily_gps']))\n",
    "                if not legacy_systems_only:\n",
    "                    data_list.append(self.get_ephemeris_dataframe(\n",
    "                        filepaths['bkg_daily_combined']))\n",
    "\n",
    "        data = pd.DataFrame()\n",
    "        data = pd.concat(data_list, ignore_index=True)\n",
    "        data.reset_index(inplace=True)\n",
    "        data.sort_values('time', inplace=True, ignore_index=True)\n",
    "        self.data = data\n",
    "\n",
    "    def get_ephemeris_dataframe(self, fileinfo, constellations=None):\n",
    "        filepath = fileinfo['filepath']\n",
    "        url = fileinfo['url']\n",
    "        directory = os.path.split(filepath)[0]\n",
    "        filename = os.path.split(filepath)[1]\n",
    "        if url == 'igs.bkg.bund.de':\n",
    "            dest_filepath = os.path.join(self.data_directory, 'igs', filename)\n",
    "        else:\n",
    "            dest_filepath = os.path.join(self.data_directory, 'nasa', filename)\n",
    "        decompressed_filename = os.path.splitext(dest_filepath)[0]\n",
    "        if not os.path.isfile(decompressed_filename):\n",
    "            if url == 'gdc.cddis.eosdis.nasa.gov':\n",
    "                secure = True\n",
    "            else:\n",
    "                secure = False\n",
    "            try:\n",
    "                self.retrieve_file(url, directory, filename,\n",
    "                                   dest_filepath, secure)\n",
    "                self.decompress_file(dest_filepath)\n",
    "            except ftplib.error_perm as err:\n",
    "                print('ftp error')\n",
    "                return pd.DataFrame()\n",
    "        if not self.leapseconds:\n",
    "            self.leapseconds = EphemerisManager.load_leapseconds(\n",
    "                decompressed_filename)\n",
    "        if constellations:\n",
    "            data = georinex.load(decompressed_filename,\n",
    "                                 use=constellations).to_dataframe()\n",
    "        else:\n",
    "            data = georinex.load(decompressed_filename).to_dataframe()\n",
    "        data.dropna(how='all', inplace=True)\n",
    "        data.reset_index(inplace=True)\n",
    "        data['source'] = decompressed_filename\n",
    "        WEEKSEC = 604800\n",
    "        data['t_oc'] = pd.to_numeric(data['time'] - datetime(1980, 1, 6, 0, 0, 0))\n",
    "        data['t_oc']  = 1e-9 * data['t_oc'] - WEEKSEC * np.floor(1e-9 * data['t_oc'] / WEEKSEC)\n",
    "        data['time'] = data['time'].dt.tz_localize('UTC')\n",
    "        data.rename(columns={'M0': 'M_0', 'Eccentricity': 'e', 'Toe': 't_oe', 'DeltaN': 'deltaN', 'Cuc': 'C_uc', 'Cus': 'C_us',\n",
    "                             'Cic': 'C_ic', 'Crc': 'C_rc', 'Cis': 'C_is', 'Crs': 'C_rs', 'Io': 'i_0', 'Omega0': 'Omega_0'}, inplace=True)\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def get_filetype(timestamp):\n",
    "        # IGS switched from .Z to .gz compression format on December 1st, 2020\n",
    "        if timestamp >= datetime(2020, 12, 1, 0, 0, 0, tzinfo=timezone.utc):\n",
    "            extension = '.gz'\n",
    "        else:\n",
    "            extension = '.Z'\n",
    "        return extension\n",
    "\n",
    "    @staticmethod\n",
    "    def load_leapseconds(filename):\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                if 'LEAP SECONDS' in line:\n",
    "                    return int(line.split()[0])\n",
    "                if 'END OF HEADER' in line:\n",
    "                    return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_constellations(satellites):\n",
    "        if type(satellites) is list:\n",
    "            systems = set()\n",
    "            for sat in satellites:\n",
    "                systems.add(sat[0])\n",
    "            return systems\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_toc(timestamp):\n",
    "        pass\n",
    "\n",
    "    def retrieve_file(self, url, directory, filename, dest_filepath, secure=False):\n",
    "        print('Retrieving ' + directory + '/' + filename + ' from ' + url)\n",
    "        ftp = self.connect(url, secure)\n",
    "        src_filepath = directory + '/' + filename\n",
    "        try:\n",
    "            with open(dest_filepath, 'wb') as handle:\n",
    "                ftp.retrbinary(\n",
    "                    'RETR ' + src_filepath, handle.write)\n",
    "        except ftplib.error_perm as err:\n",
    "            print('Failed to retrieve ' + src_filepath + ' from ' + url)\n",
    "            print(err)\n",
    "            os.remove(dest_filepath)\n",
    "            raise ftplib.error_perm\n",
    "\n",
    "    def decompress_file(self, filepath):\n",
    "        extension = os.path.splitext(filepath)[1]\n",
    "        decompressed_path = os.path.splitext(filepath)[0]\n",
    "        if extension == '.gz':\n",
    "            with gzip.open(filepath, 'rb') as f_in:\n",
    "                with open(decompressed_path, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "        elif extension == '.Z':\n",
    "            with open(filepath, 'rb') as f_in:\n",
    "                with open(decompressed_path, 'wb') as f_out:\n",
    "                    f_out.write(unlzw3.unlzw(f_in.read()))\n",
    "        os.remove(filepath)\n",
    "\n",
    "    def connect(self, url, secure):\n",
    "        if secure:\n",
    "            ftp = FTP_TLS(url)\n",
    "            ftp.login()\n",
    "            ftp.prot_p()\n",
    "        else:\n",
    "            ftp = FTP(url)\n",
    "            ftp.login()\n",
    "        return ftp\n",
    "\n",
    "    def listdir(self, url, directory, secure):\n",
    "        ftp = self.connect(url, secure)\n",
    "        dirlist = ftp.nlst(directory)\n",
    "        dirlist = [x for x in dirlist]\n",
    "        print(dirlist)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_filepaths(timestamp):\n",
    "        timetuple = timestamp.timetuple()\n",
    "        extension = EphemerisManager.get_filetype(timestamp)\n",
    "        filepaths = {}\n",
    "\n",
    "        directory = 'gnss/data/daily/' + str(timetuple.tm_year) + '/brdc/'\n",
    "        filename = 'BRDC00IGS_R_' + \\\n",
    "            str(timetuple.tm_year) + \\\n",
    "            str(timetuple.tm_yday).zfill(3) + '0000_01D_MN.rnx.gz'\n",
    "        filepaths['nasa_daily_combined'] = {\n",
    "            'filepath': directory + filename, 'url': 'gdc.cddis.eosdis.nasa.gov'}\n",
    "\n",
    "        filename = 'brdc' + str(timetuple.tm_yday).zfill(3) + \\\n",
    "            '0.' + str(timetuple.tm_year)[-2:] + 'n' + extension\n",
    "        filepaths['nasa_daily_gps'] = {\n",
    "            'filepath': directory + filename, 'url': 'gdc.cddis.eosdis.nasa.gov'}\n",
    "\n",
    "        filename = 'brdc' + str(timetuple.tm_yday).zfill(3) + \\\n",
    "            '0.' + str(timetuple.tm_year)[-2:] + 'g' + extension\n",
    "        filepaths['nasa_daily_glonass'] = {\n",
    "            'filepath': directory + filename, 'url': 'gdc.cddis.eosdis.nasa.gov'}\n",
    "\n",
    "        directory = '/IGS/BRDC/' + \\\n",
    "            str(timetuple.tm_year) + '/' + \\\n",
    "            str(timetuple.tm_yday).zfill(3) + '/'\n",
    "        filename = 'BRDC00WRD_S_' + \\\n",
    "            str(timetuple.tm_year) + \\\n",
    "            str(timetuple.tm_yday).zfill(3) + '0000_01D_MN.rnx.gz'\n",
    "        filepaths['bkg_daily_combined'] = {\n",
    "            'filepath': directory + filename, 'url': 'igs.bkg.bund.de'}\n",
    "\n",
    "        return filepaths\n",
    "\n",
    "# ****************************************************************\n",
    "import os\n",
    "\n",
    "user_home_dir = os.path.expanduser('~')  # This gets the home directory of the current user\n",
    "ephemeris_data_directory = os.path.join(user_home_dir, 'EphemerisData')\n",
    "\n",
    "manager = EphemerisManager(ephemeris_data_directory)\n",
    "\n",
    "# ****************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             t_k   delT_sv           x_k           y_k           z_k\n",
      "sv                                                                  \n",
      "G02  1559.346230 -0.000441  2.272493e+07  1.397703e+07  1.869686e+06\n",
      "G03  1559.349269  0.000350  1.282033e+07  9.125934e+06  2.126668e+07\n",
      "G04  1559.348767  0.000355  2.163307e+07  3.661372e+06  1.508204e+07\n",
      "G09  1559.340488  0.000187  2.524363e+07 -7.243609e+06  4.076006e+06\n",
      "G17  1559.337566  0.000708  2.120894e+07 -1.339452e+07  9.387903e+06\n",
      "G19  1559.337021  0.000478  1.390963e+07 -1.527713e+07  1.628561e+07\n",
      "G26  1559.336793  0.000157 -4.230809e+06  2.583960e+07  2.901617e+06\n",
      "G28  1575.337331 -0.000233 -7.182190e+06  1.354647e+07  2.167505e+07\n",
      "G31  1559.345396 -0.000228  2.778642e+06  1.904238e+07  1.792002e+07\n"
     ]
    }
   ],
   "source": [
    "def calculate_satellite_position(ephemeris, transmit_time):\n",
    "    mu = 3.986005e14\n",
    "    OmegaDot_e = 7.2921151467e-5\n",
    "    F = -4.442807633e-10\n",
    "    sv_position = pd.DataFrame()\n",
    "    sv_position['sv']= ephemeris.index\n",
    "    sv_position.set_index('sv', inplace=True)\n",
    "    sv_position['t_k'] = transmit_time - ephemeris['t_oe']\n",
    "    A = ephemeris['sqrtA'].pow(2)\n",
    "    n_0 = np.sqrt(mu / A.pow(3))\n",
    "    n = n_0 + ephemeris['deltaN']\n",
    "    M_k = ephemeris['M_0'] + n * sv_position['t_k']\n",
    "    E_k = M_k\n",
    "    err = pd.Series(data=[1]*len(sv_position.index))\n",
    "    i = 0\n",
    "    while err.abs().min() > 1e-8 and i < 10:\n",
    "        new_vals = M_k + ephemeris['e']*np.sin(E_k)\n",
    "        err = new_vals - E_k\n",
    "        E_k = new_vals\n",
    "        i += 1\n",
    "        \n",
    "    sinE_k = np.sin(E_k)\n",
    "    cosE_k = np.cos(E_k)\n",
    "    delT_r = F * ephemeris['e'].pow(ephemeris['sqrtA']) * sinE_k\n",
    "    delT_oc = transmit_time - ephemeris['t_oc']\n",
    "    sv_position['delT_sv'] = ephemeris['SVclockBias'] + ephemeris['SVclockDrift'] * delT_oc + ephemeris['SVclockDriftRate'] * delT_oc.pow(2)\n",
    "\n",
    "    v_k = np.arctan2(np.sqrt(1-ephemeris['e'].pow(2))*sinE_k,(cosE_k - ephemeris['e']))\n",
    "\n",
    "    Phi_k = v_k + ephemeris['omega']\n",
    "\n",
    "    sin2Phi_k = np.sin(2*Phi_k)\n",
    "    cos2Phi_k = np.cos(2*Phi_k)\n",
    "\n",
    "    du_k = ephemeris['C_us']*sin2Phi_k + ephemeris['C_uc']*cos2Phi_k\n",
    "    dr_k = ephemeris['C_rs']*sin2Phi_k + ephemeris['C_rc']*cos2Phi_k\n",
    "    di_k = ephemeris['C_is']*sin2Phi_k + ephemeris['C_ic']*cos2Phi_k\n",
    "\n",
    "    u_k = Phi_k + du_k\n",
    "\n",
    "    r_k = A*(1 - ephemeris['e']*np.cos(E_k)) + dr_k\n",
    "\n",
    "    i_k = ephemeris['i_0'] + di_k + ephemeris['IDOT']*sv_position['t_k']\n",
    "\n",
    "    x_k_prime = r_k*np.cos(u_k)\n",
    "    y_k_prime = r_k*np.sin(u_k)\n",
    "\n",
    "    Omega_k = ephemeris['Omega_0'] + (ephemeris['OmegaDot'] - OmegaDot_e)*sv_position['t_k'] - OmegaDot_e*ephemeris['t_oe']\n",
    "\n",
    "    sv_position['x_k'] = x_k_prime*np.cos(Omega_k) - y_k_prime*np.cos(i_k)*np.sin(Omega_k)\n",
    "    sv_position['y_k'] = x_k_prime*np.sin(Omega_k) + y_k_prime*np.cos(i_k)*np.cos(Omega_k)\n",
    "    sv_position['z_k'] = y_k_prime*np.sin(i_k)\n",
    "    return sv_position\n",
    "\n",
    "# Run the function and check out the results:\n",
    "sv_position = calculate_satellite_position(ephemeris, one_epoch['tTxSeconds'])\n",
    "print(sv_position)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial guesses of receiver clock bias and position\n",
    "b0 = 0\n",
    "x0 = np.array([0, 0, 0])\n",
    "xs = sv_position[['x_k', 'y_k', 'z_k']].to_numpy()\n",
    "\n",
    "# Apply satellite clock bias to correct the measured pseudorange values\n",
    "pr = one_epoch['PrM'] + LIGHTSPEED * sv_position['delT_sv']\n",
    "pr = pr.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## position algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32.120763136826284, 34.904095346664405, 89.78509431425482)\n",
      "-0.00569614083335575\n",
      "27.710526873227835\n"
     ]
    }
   ],
   "source": [
    "import navpy\n",
    "\n",
    "def least_squares(xs, measured_pseudorange, x0, b0):\n",
    "    dx = 100*np.ones(3)\n",
    "    b = b0\n",
    "    G = np.ones((measured_pseudorange.size, 4))\n",
    "    iterations = 0\n",
    "    while np.linalg.norm(dx) > 1e-3:\n",
    "        # Eq. (2):\n",
    "        r = np.linalg.norm(xs - x0, axis=1)\n",
    "        # Eq. (1):\n",
    "        phat = r + b0\n",
    "        # Eq. (3):\n",
    "        deltaP = measured_pseudorange - phat\n",
    "        G[:, 0:3] = -(xs - x0) / r[:, None]\n",
    "        # Eq. (4):\n",
    "        sol = np.linalg.inv(np.transpose(G) @ G) @ np.transpose(G) @ deltaP\n",
    "        # Eq. (5):\n",
    "        dx = sol[0:3]\n",
    "        db = sol[3]\n",
    "        x0 = x0 + dx\n",
    "        b0 = b0 + db\n",
    "    norm_dp = np.linalg.norm(deltaP)\n",
    "    return x0, b0, norm_dp\n",
    "\n",
    "x, b, dp = least_squares(xs, pr, x0, b0)\n",
    "print(navpy.ecef2lla(x))\n",
    "print(b/LIGHTSPEED)\n",
    "print(dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecef_list = []\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for epoch in measurements['Epoch'].unique():\n",
    "    one_epoch = measurements.loc[(measurements['Epoch'] == epoch) & (measurements['prSeconds'] < 0.1)] \n",
    "    one_epoch = one_epoch.drop_duplicates(subset='SvName').set_index('SvName')\n",
    "    if len(one_epoch.index) > 4: # At least 4 satellites are needed for a position\n",
    "        timestamp = one_epoch.iloc[0]['UnixTime'].to_pydatetime(warn=False)\n",
    "        sats = one_epoch.index.unique().tolist()\n",
    "        ephemeris = manager.get_ephemeris(timestamp, sats)\n",
    "        sv_position = calculate_satellite_position(ephemeris, one_epoch['tTxSeconds'])\n",
    "        pseudoR = one_epoch['PrM'] + LIGHTSPEED * sv_position['delT_sv']\n",
    "        cn0 = one_epoch['Cn0DbHz']\n",
    "\n",
    "        #initial guesses of receiver clock bias and position\n",
    "        b0 = 0\n",
    "        x0 = np.array([0, 0, 0])\n",
    "        xs = sv_position[['x_k', 'y_k', 'z_k']].to_numpy()\n",
    "\n",
    "        # Apply satellite clock bias to correct the measured pseudorange values\n",
    "        pr = pseudoR\n",
    "        pr = pr.to_numpy()\n",
    "\n",
    "        x, b, dp = least_squares(xs, pr, x0, b0)\n",
    "        posX, posY, posZ = x\n",
    "        Lat, Lon, Alt = navpy.ecef2lla(x)\n",
    "\n",
    "        # Append values to ecef_list with timestamp in GPSTime column\n",
    "        for idx, row in sv_position.iterrows():\n",
    "            ecef_list.append([idx, timestamp, row['x_k'], row['y_k'], row['z_k'], pseudoR[idx], cn0[idx], posX, posY, posZ, Lat, Lon, Alt])\n",
    "\n",
    "# Convert ecef_list to DataFrame and concatenate with data\n",
    "data = pd.concat([data, pd.DataFrame(ecef_list, columns=['SatPRN', 'GPSTime', 'Sat.X', 'Sat.Y', 'Sat.Z', 'Pseudo-Range', 'CN0', 'Pos.X', 'Pos.Y', 'Pos.Z', 'Lat', 'Lon', 'Alt'])], ignore_index=True)\n",
    "# change to your path\n",
    "data.to_csv('C:/Users/דניאל ריבני/Desktop/רובוטים/Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to KML file with time and animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplekml\n",
    "import pandas as pd\n",
    "import navpy\n",
    "\n",
    "# Step 1: Load the GNSS raw measurements from a CSV file\n",
    "data = pd.read_csv('data.csv', parse_dates=['GPSTime'])\n",
    "\n",
    "# Step 2: Initialize a KML object\n",
    "kml = simplekml.Kml()\n",
    "\n",
    "# Step 3: Loop through each record to add user positions to the KML\n",
    "for index, row in data.iterrows():\n",
    "    user_point = kml.newpoint(name=f\"User Position {index}\", coords=[(row['Lon'], row['Lat'], row['Alt'])])\n",
    "    user_point.timespan.begin = row['GPSTime'].isoformat()\n",
    "\n",
    "# Step 4: Convert ECEF coordinates to LLA and add satellite positions to the KML\n",
    "for index, row in data.iterrows():\n",
    "    lat, lon, alt = navpy.ecef2lla([row['Sat.X'], row['Sat.Y'], row['Sat.Z']])\n",
    "    sat_point = kml.newpoint(name=f\"Satellite {row['SatPRN']}\", coords=[(lon, lat, alt)])\n",
    "\n",
    "# Step 5: Save the KML file\n",
    "# change to your path\n",
    "kml.save('C:/Users/דניאל ריבני/Desktop/רובוטים/Computed_path.kml')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
